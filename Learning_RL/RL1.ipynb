{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rl.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushil79g/60daysUdacity/blob/master/Learning_RL/RL1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI4sCsejnwtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "from six import StringIO, b\n",
        "\n",
        "from gym import utils\n",
        "from gym.envs.toy_text import discrete\n",
        "\n",
        "LEFT = 0\n",
        "DOWN = 1\n",
        "RIGHT = 2\n",
        "UP = 3\n",
        "\n",
        "MAPS = {\n",
        "    \"4x4\": [\n",
        "        \"SFFF\",\n",
        "        \"FHFH\",\n",
        "        \"FFFH\",\n",
        "        \"HFFG\"\n",
        "    ],\n",
        "    \"8x8\": [\n",
        "        \"SFFFFFFF\",\n",
        "        \"FFFFFFFF\",\n",
        "        \"FFFHFFFF\",\n",
        "        \"FFFFFHFF\",\n",
        "        \"FFFHFFFF\",\n",
        "        \"FHHFFFHF\",\n",
        "        \"FHFFHFHF\",\n",
        "        \"FFFHFFFG\"\n",
        "    ],\n",
        "}\n",
        "\n",
        "class FrozenLakeEnv(discrete.DiscreteEnv):\n",
        "    \"\"\"\n",
        "    Winter is here. You and your friends were tossing around a frisbee at the park\n",
        "    when you made a wild throw that left the frisbee out in the middle of the lake.\n",
        "    The water is mostly frozen, but there are a few holes where the ice has melted.\n",
        "    If you step into one of those holes, you'll fall into the freezing water.\n",
        "    At this time, there's an international frisbee shortage, so it's absolutely imperative that\n",
        "    you navigate across the lake and retrieve the disc.\n",
        "    However, the ice is slippery, so you won't always move in the direction you intend.\n",
        "    The surface is described using a grid like the following\n",
        "        SFFF\n",
        "        FHFH\n",
        "        FFFH\n",
        "        HFFG\n",
        "    S : starting point, safe\n",
        "    F : frozen surface, safe\n",
        "    H : hole, fall to your doom\n",
        "    G : goal, where the frisbee is located\n",
        "    The episode ends when you reach the goal or fall in a hole.\n",
        "    You receive a reward of 1 if you reach the goal, and zero otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    metadata = {'render.modes': ['human', 'ansi']}\n",
        "\n",
        "    def __init__(self, desc=None, map_name=\"4x4\",is_slippery=True):\n",
        "        if desc is None and map_name is None:\n",
        "            raise ValueError('Must provide either desc or map_name')\n",
        "        elif desc is None:\n",
        "            desc = MAPS[map_name]\n",
        "        self.desc = desc = np.asarray(desc,dtype='c')\n",
        "        self.nrow, self.ncol = nrow, ncol = desc.shape\n",
        "\n",
        "        nA = 4\n",
        "        nS = nrow * ncol\n",
        "\n",
        "        isd = np.array(desc == b'S').astype('float64').ravel()\n",
        "        isd /= isd.sum()\n",
        "\n",
        "        P = {s : {a : [] for a in range(nA)} for s in range(nS)}\n",
        "\n",
        "        def to_s(row, col):\n",
        "            return row*ncol + col\n",
        "        def inc(row, col, a):\n",
        "            if a==0: # left\n",
        "                col = max(col-1,0)\n",
        "            elif a==1: # down\n",
        "                row = min(row+1,nrow-1)\n",
        "            elif a==2: # right\n",
        "                col = min(col+1,ncol-1)\n",
        "            elif a==3: # up\n",
        "                row = max(row-1,0)\n",
        "            return (row, col)\n",
        "\n",
        "        for row in range(nrow):\n",
        "            for col in range(ncol):\n",
        "                s = to_s(row, col)\n",
        "                for a in range(4):\n",
        "                    li = P[s][a]\n",
        "                    letter = desc[row, col]\n",
        "                    if letter in b'GH':\n",
        "                        li.append((1.0, s, 0, True))\n",
        "                    else:\n",
        "                        if is_slippery:\n",
        "                            for b in [(a-1)%4, a, (a+1)%4]:\n",
        "                                newrow, newcol = inc(row, col, b)\n",
        "                                newstate = to_s(newrow, newcol)\n",
        "                                newletter = desc[newrow, newcol]\n",
        "                                done = bytes(newletter) in b'GH'\n",
        "                                rew = float(newletter == b'G')\n",
        "                                li.append((1.0/3.0, newstate, rew, done))\n",
        "                        else:\n",
        "                            newrow, newcol = inc(row, col, a)\n",
        "                            newstate = to_s(newrow, newcol)\n",
        "                            newletter = desc[newrow, newcol]\n",
        "                            done = bytes(newletter) in b'GH'\n",
        "                            rew = float(newletter == b'G')\n",
        "                            li.append((1.0, newstate, rew, done))\n",
        "        \n",
        "        # obtain one-step dynamics for dynamic programming setting\n",
        "        self.P = P\n",
        "\n",
        "        super(FrozenLakeEnv, self).__init__(nS, nA, P, isd)\n",
        "\n",
        "    def _render(self, mode='human', close=False):\n",
        "        if close:\n",
        "            return\n",
        "        outfile = StringIO() if mode == 'ansi' else sys.stdout\n",
        "\n",
        "        row, col = self.s // self.ncol, self.s % self.ncol\n",
        "        desc = self.desc.tolist()\n",
        "        desc = [[c.decode('utf-8') for c in line] for line in desc]\n",
        "        desc[row][col] = utils.colorize(desc[row][col], \"red\", highlight=True)\n",
        "        if self.lastaction is not None:\n",
        "            outfile.write(\"  ({})\\n\".format([\"Left\",\"Down\",\"Right\",\"Up\"][self.lastaction]))\n",
        "        else:\n",
        "            outfile.write(\"\\n\")\n",
        "        outfile.write(\"\\n\".join(''.join(line) for line in desc)+\"\\n\")\n",
        "\n",
        "        if mode != 'human':\n",
        "            return outfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iloCU3wmnGjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unittest\n",
        "import copy\n",
        "from IPython.display import Markdown, display\n",
        "import numpy as np\n",
        "# from frozenlake import FrozenLakeEnv\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "    \n",
        "def policy_evaluation_soln(env, policy, gamma=1, theta=1e-8):\n",
        "    V = np.zeros(env.nS)\n",
        "    while True:\n",
        "        delta = 0\n",
        "        for s in range(env.nS):\n",
        "            Vs = 0\n",
        "            for a, action_prob in enumerate(policy[s]):\n",
        "                for prob, next_state, reward, done in env.P[s][a]:\n",
        "                    Vs += action_prob * prob * (reward + gamma * V[next_state])\n",
        "            delta = max(delta, np.abs(V[s]-Vs))\n",
        "            V[s] = Vs\n",
        "        if delta < theta:\n",
        "            break\n",
        "    return V\n",
        "\n",
        "def q_from_v_soln(env, V, s, gamma=1):\n",
        "    q = np.zeros(env.nA)\n",
        "    for a in range(env.nA):\n",
        "        for prob, next_state, reward, done in env.P[s][a]:\n",
        "            q[a] += prob * (reward + gamma * V[next_state])\n",
        "    return q\n",
        "\n",
        "def policy_improvement_soln(env, V, gamma=1):\n",
        "    policy = np.zeros([env.nS, env.nA]) / env.nA\n",
        "    for s in range(env.nS):\n",
        "        q = q_from_v_soln(env, V, s, gamma)\n",
        "        best_a = np.argwhere(q==np.max(q)).flatten()\n",
        "        policy[s] = np.sum([np.eye(env.nA)[i] for i in best_a], axis=0)/len(best_a)\n",
        "    return policy\n",
        "\n",
        "def policy_iteration_soln(env, gamma=1, theta=1e-8):\n",
        "    policy = np.ones([env.nS, env.nA]) / env.nA\n",
        "    while True:\n",
        "        V = policy_evaluation_soln(env, policy, gamma, theta)\n",
        "        new_policy = policy_improvement_soln(env, V)\n",
        "        if (new_policy == policy).all():\n",
        "            break;\n",
        "        policy = copy.copy(new_policy)\n",
        "    return policy, V\n",
        "\n",
        "env = FrozenLakeEnv()\n",
        "random_policy = np.ones([env.nS, env.nA]) / env.nA\n",
        "\n",
        "class Tests(unittest.TestCase):\n",
        "\n",
        "    def policy_evaluation_check(self, policy_evaluation):\n",
        "        soln = policy_evaluation_soln(env, random_policy)\n",
        "        to_check = policy_evaluation(env, random_policy)\n",
        "        np.testing.assert_array_almost_equal(soln, to_check)\n",
        "\n",
        "    def q_from_v_check(self, q_from_v):\n",
        "        V = policy_evaluation_soln(env, random_policy)\n",
        "        soln = np.zeros([env.nS, env.nA])\n",
        "        to_check = np.zeros([env.nS, env.nA])\n",
        "        for s in range(env.nS):\n",
        "            soln[s] = q_from_v_soln(env, V, s)\n",
        "            to_check[s] = q_from_v(env, V, s)\n",
        "        np.testing.assert_array_almost_equal(soln, to_check)\n",
        "\n",
        "    def policy_improvement_check(self, policy_improvement):\n",
        "        V = policy_evaluation_soln(env, random_policy)\n",
        "        new_policy = policy_improvement(env, V)\n",
        "        new_V = policy_evaluation_soln(env, new_policy)\n",
        "        self.assertTrue(np.all(new_V >= V))\n",
        "\n",
        "    def policy_iteration_check(self, policy_iteration):\n",
        "        policy_soln, _ = policy_iteration_soln(env)\n",
        "        policy_to_check, _ = policy_iteration(env)\n",
        "        soln = policy_evaluation_soln(env, policy_soln)\n",
        "        to_check = policy_evaluation_soln(env, policy_to_check)\n",
        "        np.testing.assert_array_almost_equal(soln, to_check)\n",
        "\n",
        "    def truncated_policy_iteration_check(self, truncated_policy_iteration):\n",
        "        self.policy_iteration_check(truncated_policy_iteration)\n",
        "\n",
        "    def value_iteration_check(self, value_iteration):\n",
        "        self.policy_iteration_check(value_iteration)\n",
        "\n",
        "check = Tests()\n",
        "\n",
        "def run_check(check_name, func):\n",
        "    try:\n",
        "        getattr(check, check_name)(func)\n",
        "    except check.failureException as e:\n",
        "        printmd('**<span style=\"color: red;\">PLEASE TRY AGAIN</span>**')\n",
        "        return\n",
        "    printmd('**<span style=\"color: green;\">PASSED</span>**')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXI8Tyvqn-5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(V):\n",
        "\t# reshape value function\n",
        "\tV_sq = np.reshape(V, (4,4))\n",
        "\n",
        "\t# plot the state-value function\n",
        "\tfig = plt.figure(figsize=(6, 6))\n",
        "\tax = fig.add_subplot(111)\n",
        "\tim = ax.imshow(V_sq, cmap='cool')\n",
        "\tfor (j,i),label in np.ndenumerate(V_sq):\n",
        "\t    ax.text(i, j, np.round(label, 5), ha='center', va='center', fontsize=14)\n",
        "\tplt.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
        "\tplt.title('State-Value Function')\n",
        "\tplt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdWrAxi9lvAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "import check_test"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}