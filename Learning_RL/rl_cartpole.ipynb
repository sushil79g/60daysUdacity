{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rl_cartpole.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushil79g/60daysUdacity/blob/master/Learning_RL/rl_cartpole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4nC6DEBADzM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "32f359c7-430f-4700-dc13-558a67aaaca5"
      },
      "source": [
        "!pip install pyglet==1.3.2\n",
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyglet==1.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.3.2) (0.16.0)\n",
            "Installing collected packages: pyglet\n",
            "  Found existing installation: pyglet 1.4.1\n",
            "    Uninstalling pyglet-1.4.1:\n",
            "      Successfully uninstalled pyglet-1.4.1\n",
            "Successfully installed pyglet-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzRS0trz2ycs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2lDyO3Q28O3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pyglet.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLg8Xplv3Npx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkDZ1u9t3dU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ-SBWW1MPzr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "aeedf9e0-422c-45d4-a327-7f1c9976617c"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x300x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x300x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POPjLJkN3oTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('CartPole-v0').unwrapped"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcNBO-da30OG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "is_python = 'inline' in matplotlib.get_backend()\n",
        "if is_python:\n",
        "    from IPython import display\n",
        "plt.ion()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61VsgU3k4Cb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvhqeY5T4OmQ",
        "colab_type": "text"
      },
      "source": [
        "# store the transitional result observe by the agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT9Uerb54Jsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Transition = namedtuple('Transition',('state','action','next_state','reward'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx5Kw_dw5BnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReplayMemory(object):\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "        \n",
        "    def push(self, *args):\n",
        "        #save transition\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "        \n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRwbqJHX556e",
        "colab_type": "text"
      },
      "source": [
        "### DQN ALGORITHM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE1t6I-652Rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "        self.head = nn.Linear(448, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        return self.head(x.view(x.size(0), -1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wao9qdZc8NCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resize = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Resize(40, interpolation=Image.CUBIC),\n",
        "    T.ToTensor()\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-hy8JPM8lKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#screen adjustment\n",
        "screen_width = 600"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLGumQJK9KW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cart_location():\n",
        "    world_width = env.x_threshold * 2\n",
        "    scale = screen_width / world_width\n",
        "    return int(env.state[0] * scale + screen_width/2.0) #middle of cart"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR6B7su39h5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "376731f4-eb23-4321-814e-45074b4461af"
      },
      "source": [
        "def get_screen():\n",
        "    screen = env.render(mode='rgb_array').transpose(\n",
        "        (2, 0, 1))  # transpose into torch order (CHW)\n",
        "    # Strip off the top and bottom of the screen\n",
        "    screen = screen[:, 160:320]\n",
        "    view_width = 320\n",
        "    cart_location = get_cart_location()\n",
        "    if cart_location < view_width // 2:\n",
        "        slice_range = slice(view_width)\n",
        "    elif cart_location > (screen_width - view_width // 2):\n",
        "        slice_range = slice(-view_width, None)\n",
        "    else:\n",
        "        slice_range = slice(cart_location - view_width // 2,\n",
        "                            cart_location + view_width // 2)\n",
        "    # Strip off the edges, so that we have a square image centered on a cart\n",
        "    screen = screen[:, :, slice_range]\n",
        "    # Convert to float, rescare, convert to torch tensor\n",
        "    # (this doesn't require a copy)\n",
        "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
        "    screen = torch.from_numpy(screen)\n",
        "    # Resize, and add a batch dimension (BCHW)\n",
        "    return resize(screen).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "env.reset()\n",
        "plt.figure()\n",
        "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),interpolation='none')\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADWCAYAAADBwHkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1Zmc1rl9kHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.999\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 200\n",
        "TARGET_UPDATE = 10\n",
        "\n",
        "policy_net = DQN().to(device)\n",
        "target_net = DQN().to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.RMSprop(policy_net.parameters())\n",
        "memory = ReplayMemory(10000)\n",
        "steps_done = 0\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) *  math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            return policy_net(state).max(1)[1].view(1,1)\n",
        "    else:\n",
        "        return torch.tensor([[random.randrange(2)]], device=device, dtype=torch.long)\n",
        "episode_durations = []\n",
        "\n",
        "def plot_durations():\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.1)  # pause a bit so that plots are updated\n",
        "    if is_python:\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(plt.gcf())\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUFzBzUq_8_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation).\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOOBqPS2TPgF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "daba3985-ffae-40e0-a3e5-3f26c0801516"
      },
      "source": [
        "num_episodes = 50\n",
        "for i_episode in range(num_episodes):\n",
        "    # Initialize the environment and state\n",
        "    env.reset()\n",
        "    last_screen = get_screen()\n",
        "    current_screen = get_screen()\n",
        "    state = current_screen - last_screen\n",
        "    for t in count():\n",
        "        # Select and perform an action\n",
        "        action = select_action(state)\n",
        "        _, reward, done, _ = env.step(action.item())\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "\n",
        "        # Observe new state\n",
        "        last_screen = current_screen\n",
        "        current_screen = get_screen()\n",
        "        if not done:\n",
        "            next_state = current_screen - last_screen\n",
        "        else:\n",
        "            next_state = None\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "        # Perform one step of the optimization (on the target network)\n",
        "        optimize_model()\n",
        "        if done:\n",
        "            episode_durations.append(t + 1)\n",
        "            plot_durations()\n",
        "            break\n",
        "    # Update the target network\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "print('Complete')\n",
        "env.render()\n",
        "env.close()\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnbx87MAkaG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}