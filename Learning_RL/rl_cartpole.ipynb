{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rl_cartpole.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushil79g/60daysUdacity/blob/master/Learning_RL/rl_cartpole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4nC6DEBADzM",
        "colab_type": "code",
        "outputId": "8fde49e9-47d6-4795-a5db-eae36f5f4b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install pyglet==1.3.2\n",
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyglet==1.3.2 in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.3.2) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzRS0trz2ycs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2lDyO3Q28O3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pyglet.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLg8Xplv3Npx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkDZ1u9t3dU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ-SBWW1MPzr",
        "colab_type": "code",
        "outputId": "7f500e57-3e7b-43d7-caf0-340ce178552a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x300x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x300x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POPjLJkN3oTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('CartPole-v0').unwrapped"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcNBO-da30OG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "is_python = 'inline' in matplotlib.get_backend()\n",
        "if is_python:\n",
        "    from IPython import display\n",
        "plt.ion()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61VsgU3k4Cb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvhqeY5T4OmQ",
        "colab_type": "text"
      },
      "source": [
        "# store the transitional result observe by the agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT9Uerb54Jsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Transition = namedtuple('Transition',('state','action','next_state','reward'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx5Kw_dw5BnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReplayMemory(object):\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "        \n",
        "    def push(self, *args):\n",
        "        #save transition\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "        \n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRwbqJHX556e",
        "colab_type": "text"
      },
      "source": [
        "### DQN ALGORITHM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE1t6I-652Rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "        self.head = nn.Linear(448, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        return self.head(x.view(x.size(0), -1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wao9qdZc8NCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resize = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Resize(40, interpolation=Image.CUBIC),\n",
        "    T.ToTensor()\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-hy8JPM8lKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#screen adjustment\n",
        "screen_width = 600"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLGumQJK9KW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cart_location():\n",
        "    world_width = env.x_threshold * 2\n",
        "    scale = screen_width / world_width\n",
        "    return int(env.state[0] * scale + screen_width/2.0) #middle of cart"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR6B7su39h5r",
        "colab_type": "code",
        "outputId": "90cd079a-1563-4d77-bea2-bbaa06098f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "def get_screen():\n",
        "    screen = env.render(mode='rgb_array').transpose(\n",
        "        (2, 0, 1))  # transpose into torch order (CHW)\n",
        "    # Strip off the top and bottom of the screen\n",
        "    screen = screen[:, 160:320]\n",
        "    view_width = 320\n",
        "    cart_location = get_cart_location()\n",
        "    if cart_location < view_width // 2:\n",
        "        slice_range = slice(view_width)\n",
        "    elif cart_location > (screen_width - view_width // 2):\n",
        "        slice_range = slice(-view_width, None)\n",
        "    else:\n",
        "        slice_range = slice(cart_location - view_width // 2,\n",
        "                            cart_location + view_width // 2)\n",
        "    # Strip off the edges, so that we have a square image centered on a cart\n",
        "    screen = screen[:, :, slice_range]\n",
        "    # Convert to float, rescare, convert to torch tensor\n",
        "    # (this doesn't require a copy)\n",
        "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
        "    screen = torch.from_numpy(screen)\n",
        "    # Resize, and add a batch dimension (BCHW)\n",
        "    return resize(screen).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "env.reset()\n",
        "plt.figure()\n",
        "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),interpolation='none')\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADWCAYAAADBwHkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1Zmc1rl9kHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.999\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 200\n",
        "TARGET_UPDATE = 10\n",
        "\n",
        "policy_net = DQN().to(device)\n",
        "target_net = DQN().to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.RMSprop(policy_net.parameters())\n",
        "memory = ReplayMemory(10000)\n",
        "steps_done = 0\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) *  math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            return policy_net(state).max(1)[1].view(1,1)\n",
        "    else:\n",
        "        return torch.tensor([[random.randrange(2)]], device=device, dtype=torch.long)\n",
        "episode_durations = []\n",
        "\n",
        "def plot_durations():\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(1)  # pause a bit so that plots are updated\n",
        "    if is_python:\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(plt.gcf())\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUFzBzUq_8_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation).\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOOBqPS2TPgF",
        "colab_type": "code",
        "outputId": "82ce455f-7af5-45dc-9a8d-cca12119fa1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "num_episodes = 500\n",
        "for i_episode in range(num_episodes):\n",
        "    # Initialize the environment and state\n",
        "    env.reset()\n",
        "    last_screen = get_screen()\n",
        "    current_screen = get_screen()\n",
        "    state = current_screen - last_screen\n",
        "    for t in count():\n",
        "        # Select and perform an action\n",
        "        action = select_action(state)\n",
        "        _, reward, done, _ = env.step(action.item())\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "\n",
        "        # Observe new state\n",
        "        last_screen = current_screen\n",
        "        current_screen = get_screen()\n",
        "        if not done:\n",
        "            next_state = current_screen - last_screen\n",
        "        else:\n",
        "            next_state = None\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "        # Perform one step of the optimization (on the target network)\n",
        "        optimize_model()\n",
        "        if done:\n",
        "            episode_durations.append(t + 1)\n",
        "            plot_durations()\n",
        "            break\n",
        "    # Update the target network\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "print('Complete')\n",
        "env.render()\n",
        "env.close()\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur02hCGSdKNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}